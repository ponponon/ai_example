from transformers import AutoTokenizer, AutoModel


tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm3-6b", trust_remote_code=True, device='cuda')
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])

import time

tt = []

from loguru import logger


def func(filepath:str):
    with open(filepath, 'r', encoding='utf-8') as file:
        content = file.read()

    lines = [
        content
    ]

    history=[]

    for line in lines:

        text = f"""{line}"""

        s = time.time()
        response, history = model.chat(tokenizer, text, history=history)
        e = time.time()

        tt.append(e-s)

        logger.debug(text)
        logger.debug(response)
        logger.debug(f'è€—æ—¶: {round(e-s,3)} ç§’')
        print('-----------------------------------------------')

        # with open('output-30.log', 'a', encoding='utf-8') as out_file:
        #     out_file.write(f'Question ğŸ‘‰ {text}')
        #     out_file.write('\n')
        #     out_file.write(f'Answer:ğŸ‘‡\n{response}')
        #     out_file.write('\n\n-----------------------------------------------')
        #     out_file.write('\n')
        #     out_file.write('\n')
        #     out_file.write('\n')

    print(f'æ€»è€—æ—¶: {sum(tt)}ç§’')
    print(f'å¹³å‡å•ä¸ªè€—æ—¶: {sum(tt)/len(tt)}ç§’')


func('/home/pon/code/me/ai_example/examples/ChatGLM3/q1.txt')